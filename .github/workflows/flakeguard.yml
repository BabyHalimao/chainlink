name: Flakeguard

on:
  workflow_call:
    inputs:
      repoUrl:
        required: true
        type: string
        description: 'The URL of the repository to compare changes for detecting flaky tests.'
      projectPath:
        required: true
        type: string
        description: 'The path to the project to run the flaky test detection.'
        default: '.'  
      baseRef:
        required: true
        type: string
        description: 'The base reference or branch to compare changes for detecting flaky tests.'
      headRef:
        required: false
        type: string
        description: 'The head reference or branch to compare changes for detecting flaky tests. Default is the current branch.'
      runAllTests:
        required: false
        type: boolean
        description: 'Run all tests in the project.'
        default: false    
      maxPassRatio:
        required: false
        type: string
        description: 'The maximum (non-inclusive) pass ratio threshold for a test to be considered a failure. Any tests below this pass rate will be considered flaky.'
        default: '1.0'
      findByTestFilesDiff:
        required: false
        type: boolean
        description: 'Find new or updated test packages by comparing test files diff.'
        default: true
      findByAffectedPackages:
        required: false
        type: boolean
        description: 'Find new or updated test packages by comparing affected packages.'
        default: true
      slackNotificationAfterTestsChannelId:
        description: "Slack channel ID to send the notification to for failed tests."
        required: false
        type: string
      extraArgs:
        required: false
        type: string
        default: '{}'
        description: 'JSON of extra arguments for the workflow.'
    secrets:
      SLACK_BOT_TOKEN:
        required: false

env:
  GIT_HEAD_REF: ${{ inputs.headRef || github.ref }}
  SKIPPED_TESTS: ${{ fromJson(inputs.extraArgs)['skipped_tests'] || '' }} # Comma separated list of test names to skip running in the flaky detector. Related issue: TT-1823
  DEFAULT_MAX_RUNNER_COUNT: ${{ fromJson(inputs.extraArgs)['default_max_runner_count'] || '8' }} # The default maximum number of GitHub runners to use for parallel test execution.
  ALL_TESTS_RUNNER_COUNT: ${{ fromJson(inputs.extraArgs)['all_tests_runner_count'] || '2' }} # The number of GitHub runners to use when running all tests `runAllTests=true`.
  TEST_REPEAT_COUNT: ${{ fromJson(inputs.extraArgs)['test_repeat_count'] || '5' }} # The number of times each runner should run a test to detect flaky tests.
  RUN_WITH_RACE: ${{ fromJson(inputs.extraArgs)['run_with_race'] || 'true' }} # Whether to run tests with -race flag.
  RUN_WITH_SHUFFLE: ${{ fromJson(inputs.extraArgs)['run_with_shuffle'] || 'false' }} # Whether to run tests with -shuffle flag.
  SHUFFLE_SEED: ${{ fromJson(inputs.extraArgs)['shuffle_seed'] || '999' }} # The seed to use when -shuffle flag is enabled. Requires RUN_WITH_SHUFFLE to be true.
  ALL_TESTS_RUNNER: ${{ fromJson(inputs.extraArgs)['all_tests_runner'] || 'ubuntu22.04-32cores-128GB' }} # The runner to use for running all tests.
  DEFAULT_RUNNER: 'ubuntu-latest' # The default runner to use for running tests.
  UPLOAD_ALL_TEST_RESULTS: ${{ fromJson(inputs.extraArgs)['upload_all_test_results'] || 'false' }} # Whether to upload all test results as artifacts.
  PRINT_FAILED_TESTS: ${{ fromJson(inputs.extraArgs)['print_failed_tests'] || 'false' }} # Whether to print failed tests in the GitHub console.

jobs:
  get-tests:
    name: Get Tests To Run
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.split-packages.outputs.matrix }}
      workflow_id: ${{ steps.gen_id.outputs.workflow_id }}
      changed_test_files: ${{ steps.find-changed-test-files.outputs.test_files }}
      affected_test_packages: ${{ steps.get-tests.outputs.packages }}
      git_head_sha: ${{ steps.get_commit_sha.outputs.git_head_sha }}
      git_head_short_sha: ${{ steps.get_commit_sha.outputs.git_head_short_sha }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v4.1.2
        with:
          fetch-depth: 0
          ref: ${{ env.GIT_HEAD_REF }}

      - name: Get commit SHA
        id: get_commit_sha
        run: |
          git_head_sha=$(git rev-parse HEAD)
          git_head_short_sha=$(git rev-parse --short HEAD)
          echo "git_head_sha=$git_head_sha" >> $GITHUB_OUTPUT
          echo "git_head_short_sha=$git_head_short_sha" >> $GITHUB_OUTPUT          

      - name: Set up Go 1.21.9
        uses: actions/setup-go@v5.0.2
        with:
          cache: false

      - name: Install flakeguard
        shell: bash
        run: go install github.com/smartcontractkit/chainlink-testing-framework/tools/flakeguard@04bfae2602c015036f366a8dd4e7a619096cc516 # flakguard@0.1.0

      - name: Find new or updated test packages
        if: ${{ inputs.runAllTests == false }}
        id: get-tests
        shell: bash
        env:
          # Needed to run go test -list
          CL_DATABASE_URL: postgresql://postgres@localhost:5432/chainlink_test?sslmode=disable
        run: |
          PATH=$PATH:$(go env GOPATH)/bin
          export PATH

          PACKAGES=$(flakeguard find --find-by-test-files-diff=${{ inputs.findByTestFilesDiff }} --find-by-affected-packages=${{ inputs.findByAffectedPackages }} --base-ref=origin/${{ inputs.baseRef }} --project-path=${{ inputs.projectPath }})
          echo $PACKAGES
          echo "packages=$PACKAGES" >> $GITHUB_OUTPUT

      - name: Find changed test files 
        if: ${{ inputs.runAllTests == false }}
        id: find-changed-test-files
        shell: bash
        env:
          # Needed to run go test -list
          CL_DATABASE_URL: postgresql://postgres@localhost:5432/chainlink_test?sslmode=disable
        run: |
          PATH=$PATH:$(go env GOPATH)/bin
          export PATH

          TEST_FILES=$(flakeguard find --only-show-changed-test-files=true --base-ref=origin/${{ inputs.baseRef }} --project-path=${{ inputs.projectPath }})
          echo $TEST_FILES
          echo "test_files=$TEST_FILES" >> $GITHUB_OUTPUT
          
      - name: Split test packages into groups
        id: split-packages
        shell: bash
        run: |
          if [[ "${{ inputs.runAllTests }}" == "true" ]]; then
            # Use ALL_TESTS_RUNNER for a specified number of groups, each with "./..." to run all tests
            ALL_TESTS_RUNNER_COUNT=${{ env.ALL_TESTS_RUNNER_COUNT }}
            
            # Create the JSON array dynamically based on ALL_TESTS_RUNNER_COUNT
            json_groups=$(jq -nc --argjson count "$ALL_TESTS_RUNNER_COUNT" \
              '[range(0; $count) | { "testPackages": "./...", "runs_on": "'"${{ env.ALL_TESTS_RUNNER }}"'" }]')
              
            echo "$json_groups"
            echo "matrix<<EOF" >> $GITHUB_OUTPUT
            echo "$json_groups" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
            exit 0
          fi

          PACKAGES=(${{ steps.get-tests.outputs.packages }})
          DESIRED_GROUP_COUNT=$((${{ env.DEFAULT_MAX_RUNNER_COUNT }}))
          TOTAL_PACKAGES=${#PACKAGES[@]}

          # Number of groups should be no more than the number of packages
          MAX_GROUP_COUNT=$(($TOTAL_PACKAGES < $DESIRED_GROUP_COUNT ? $TOTAL_PACKAGES : $DESIRED_GROUP_COUNT))
          BASE_GROUP_SIZE=$(($TOTAL_PACKAGES / $MAX_GROUP_COUNT))
          EXTRA=$(($TOTAL_PACKAGES % $MAX_GROUP_COUNT))

          groups=()

          current_index=0
          for (( i=0; i < $MAX_GROUP_COUNT; i++ )); do
              # Determine the number of packages for the current group
              group_size=$BASE_GROUP_SIZE
              if [[ $i -lt $EXTRA ]]; then
                  group_size=$(($group_size + 1))
              fi
              
              # Extract the packages for the current group
              if [[ $group_size -gt 0 ]]; then
                  group=("${PACKAGES[@]:current_index:group_size}")
                  groups+=("{\"testPackages\":\"$(IFS=,; echo "${group[*]}")\", \"runs_on\":\"${{ env.DEFAULT_RUNNER }}\"}")
                  current_index=$(($current_index + $group_size))
              fi
          done

          # Convert groups array into a JSON array
          json_groups=$(printf '%s\n' "${groups[@]}" | jq -s .)
          echo "$json_groups"
          echo "matrix<<EOF" >> $GITHUB_OUTPUT
          echo "$json_groups" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Generate random workflow id
        id: gen_id
        shell: bash
        run: echo "workflow_id=$(uuidgen)" >> "$GITHUB_OUTPUT"          

  run-tests:
    name: Run Tests
    needs: get-tests
    runs-on: ${{ matrix.runs_on }}
    if: ${{ needs.get-tests.outputs.matrix != '' && needs.get-tests.outputs.matrix != '[]' }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix: 
        include: ${{ fromJson(needs.get-tests.outputs.matrix) }}
    env:
      DB_URL: postgresql://postgres:postgres@localhost:5432/chainlink_test?sslmode=disable
    steps:
      - name: Checkout repository
        uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v4.1.2
        with:
          ref: ${{ env.GIT_HEAD_REF }}

      - name: Setup NodeJS
        uses: ./.github/actions/setup-nodejs
        with:
          prod: "true"
      - name: Setup Go
        uses: ./.github/actions/setup-go
        with:
          restore-build-cache-only: "true"
      - name: Setup Solana
        uses: ./.github/actions/setup-solana
      - name: Setup wasmd
        uses: ./.github/actions/setup-wasmd
      - name: Setup Postgres
        uses: ./.github/actions/setup-postgres
      - name: Touching core/web/assets/index.html
        run: mkdir -p core/web/assets && touch core/web/assets/index.html
      - name: Download Go vendor packages
        run: go mod download
      - name: Build binary
        run: go build -o chainlink.test .
      - name: Setup DB
        run: ./chainlink.test local db preparetest
        env:
          CL_DATABASE_URL: ${{ env.DB_URL }}        
      - name: Install LOOP Plugins
        run: |
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-feeds)
          go install ./cmd/chainlink-feeds
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-data-streams)
          go install ./mercury/cmd/chainlink-mercury
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-solana)
          go install ./pkg/solana/cmd/chainlink-solana
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-starknet/relayer)
          go install ./pkg/chainlink/cmd/chainlink-starknet
          popd

      - name: Go mod tidy
        shell: bash
        run: |
          cd ${{ inputs.projectPath }}
          go mod tidy

      - name: Generate random id
        id: gen_id
        run: echo "id=$(uuidgen)" >> "$GITHUB_OUTPUT"

      - name: Install flakeguard
        shell: bash
        run: go install github.com/smartcontractkit/chainlink-testing-framework/tools/flakeguard@04bfae2602c015036f366a8dd4e7a619096cc516 # flakguard@0.1.0

      - name: Run tests with flakeguard
        shell: bash
        run: flakeguard run --project-path=${{ inputs.projectPath }} --test-packages=${{ matrix.testPackages }} --run-count=${{ env.TEST_REPEAT_COUNT }} --max-pass-ratio=${{ inputs.maxPassRatio }} --race=${{ env.RUN_WITH_RACE }} --shuffle=${{ env.RUN_WITH_SHUFFLE }} --shuffle-seed=${{ env.SHUFFLE_SEED }} --skip-tests=${{ env.SKIPPED_TESTS }} --print-failed-tests=${{ env.PRINT_FAILED_TESTS }} --output-json=test-result.json
        env:
          CL_DATABASE_URL: ${{ env.DB_URL }}

      - name: Upload test result as artifact
        if: always()
        uses: actions/upload-artifact@v4.4.3
        with:
          name: test-result-${{ needs.get-tests.outputs.workflow_id }}-${{ steps.gen_id.outputs.id }}
          path: test-result.json
          retention-days: 1   

  report:
    needs: [get-tests, run-tests]
    if: always()
    name: Report
    runs-on: ubuntu-latest
    outputs:
      test_results: ${{ steps.set_test_results.outputs.results }}
    steps:
      - name: Set Pretty Project Path
        id: set_project_path_pretty
        run: |
          if [ "${{ inputs.projectPath }}" = "." ]; then
            echo "path=github.com/${{ github.repository }}" >> $GITHUB_OUTPUT
          else
            echo "path=github.com/${{ github.repository }}/${{ inputs.projectPath }}" >> $GITHUB_OUTPUT
          fi

      - name: Download all test result artifacts
        uses: actions/download-artifact@v4.1.8
        with:
          path: test_results
          pattern:
            test-result-${{ needs.get-tests.outputs.workflow_id }}-*
            
      - name: Install flakeguard
        shell: bash
        run: go install github.com/smartcontractkit/chainlink-testing-framework/tools/flakeguard@04bfae2602c015036f366a8dd4e7a619096cc516 # flakguard@0.1.0
                
      - name: Set combined test results
        id: set_test_results
        shell: bash
        run: |
          set -e  # Exit immediately if a command exits with a non-zero status.
          if [ -d "test_results" ]; then
            cd test_results
            ls -R .

            # Fix flakeguard binary path
            PATH=$PATH:$(go env GOPATH)/bin
            export PATH

            # Use flakeguard to aggregate all test results
            flakeguard aggregate-results --results-path . --output-results ../all_tests.json

            # Count all tests
            ALL_TESTS_COUNT=$(jq '.Results | length' ../all_tests.json)
            echo "All tests count: $ALL_TESTS_COUNT"
            echo "all_tests_count=$ALL_TESTS_COUNT" >> "$GITHUB_OUTPUT"

            # Use flakeguard to filter and output failed tests based on MaxPassRatio
            flakeguard aggregate-results --filter-failed=true --max-pass-ratio=${{ inputs.maxPassRatio }} --results-path . --output-results ../failed_tests.json --output-logs ../failed_test_logs.json --project-path=${{ inputs.projectPath }} --codeowners-path=.github/CODEOWNERS

            # Count failed tests
            if [ -f "../failed_tests.json" ]; then
              FAILED_TESTS_COUNT=$(jq '.Results | length' ../failed_tests.json)
            else
              FAILED_TESTS_COUNT=0
            fi
            echo "Failed tests count: $FAILED_TESTS_COUNT"
            echo "failed_tests_count=$FAILED_TESTS_COUNT" >> "$GITHUB_OUTPUT"
          else
            echo "No test results directory found."
            echo "all_tests_count=0" >> "$GITHUB_OUTPUT"
            echo "failed_tests_count=0" >> "$GITHUB_OUTPUT"
          fi   

      - name: Tests Summary
        if: always()
        run: |
          FILE_SIZE=$(wc -c < all_tests.md)
                    echo "File size: $FILE_SIZE bytes"
          SIZE_LIMIT=$((1024 * 1024))

          if [ "$FILE_SIZE" -le "$SIZE_LIMIT" ]; then
            cat all_tests.md >> $GITHUB_STEP_SUMMARY
          else
            echo "**We found flaky tests, so many flaky tests that the summary is too large for github actions step summaries!**" >> $GITHUB_STEP_SUMMARY
            echo "**Please see logs, or the attached `all-summary.md` artifact**" >> $GITHUB_STEP_SUMMARY
            cat all_tests.md
          fi

      - name: Upload All Tests Summary as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: all_tests.md
          name: all-summary.md
          retention-days: 7

      - name: Upload All Test Results as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: all_tests.json
          name: all-test-results.json
          retention-days: 7
      
      - name: Upload Failed Tests Summary as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: failed_tests.md
          name: failed-summary.md
          retention-days: 7

      - name: Upload Failed Test Results as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: failed_tests.json
          name: failed-test-results.json
          retention-days: 7        

      - name: Upload Failed Test Logs as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: failed_test_logs.json
          name: failed-test-logs.json
          retention-days: 7             

      - name: Upload All Test Results as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 && env.UPLOAD_ALL_TEST_RESULTS == 'true' }}
        uses: actions/upload-artifact@v4.4.3
        with:
          path: all_tests.json
          name: all-test-results.json
          retention-days: 7

      - name: Post comment on PR if flaky tests found
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 && github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            const fs = require('fs');
            const prNumber = context.payload.pull_request.number;
            const commentBody = fs.readFileSync('../all_tests.md', 'utf8');

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: commentBody
            });

      - name: Send Slack message
        uses: slackapi/slack-github-action@6c661ce58804a1a20f6dc5fbee7f0381b469e001 # v1.25.0
        if: ${{ inputs.slackNotificationAfterTestsChannelId != '' && fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        id: slack
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: ${{ inputs.slackNotificationAfterTestsChannelId }}
          payload: |
            {
              "attachments": [
                {
                  "color": "${{ contains(join(needs.*.result, ','), 'failure') && '#C62828' || contains(join(needs.*.result, ','), 'cancelled') && '#FFA000' || '2E7D32' }}",
                  "blocks": [
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "Flaky Test Detector for `${{ steps.set_project_path_pretty.outputs.path }}` project - ${{ contains(join(needs.*.result, ','), 'failure') && 'Failed :x:' || contains(join(needs.*.result, ','), 'cancelled') && 'Was cancelled :warning:' || 'Passed :white_check_mark:' }}"
                      }
                    },
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "Ran changed tests between `${{ inputs.baseRef }}` and `${{ needs.get-tests.outputs.git_head_short_sha }}` (`${{ env.GIT_HEAD_REF }}`)."
                      }
                    },
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "${{ format('<{0}/{1}/actions/runs/{2}|View Flaky Detector Details> | <{3}/compare/{4}...{5}#files_bucket|Compare Changes>{6}', github.server_url, github.repository, github.run_id, inputs.repoUrl, inputs.baseRef, needs.get-tests.outputs.git_head_sha, github.event_name == 'pull_request' && format(' | <{0}|View PR>', github.event.pull_request.html_url) || '') }}"
                      }
                    }                 
                  ]
                }
              ]
            }
